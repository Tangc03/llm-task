{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9e42818-80ae-4916-82c1-54d98249ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import glob\n",
    "import tqdm\n",
    "from torchvision import transforms\n",
    "\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "# set gpu id\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f155aaa-315b-4f5f-9138-64bf2a712ff3",
   "metadata": {},
   "source": [
    "### Data Loading Class for GSM8K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df774be7-96e2-4b52-8fa7-d3a1400c9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GSM8KDataset(Dataset):\n",
    "    def __init__(self, split):\n",
    "        root = \"datasets/grade_school_math/data\"\n",
    "        file_path = os.path.join(root, f\"{split}.jsonl\")\n",
    "        with open(file_path, 'r') as f:\n",
    "            self.data = [json.loads(line) for line in f]\n",
    "        print(f\"Loaded {len(self.data)} examples.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return {\n",
    "            \"question\": item[\"question\"],\n",
    "            \"answer\": item[\"answer\"]\n",
    "        }\n",
    "\n",
    "def gsm8k_dataloader(batch_size=32, split=\"train\"):\n",
    "    dataset = GSM8KDataset(split)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=(split == \"train\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fb69d5-56c0-47fb-8c50-39488a5069e1",
   "metadata": {},
   "source": [
    "### Qwen2-1.5B Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e75945c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json\n",
    "import time\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import logging\n",
    "os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
    "\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa6bb46-a31f-48a4-80d6-f66f3ebc8b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qwen_model():\n",
    "    model_path = \"checkpoints/Qwen2-1.5B\"\n",
    "    print(f\"Attempting to load model from local path: {model_path}\")\n",
    "    \n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True).to(device)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model or tokenizer: {e}\")\n",
    "        raise\n",
    "    \n",
    "    return model, tokenizer, device\n",
    "\n",
    "def llm_inference():\n",
    "    model, tokenizer, device = load_qwen_model()\n",
    "    dataloader = gsm8k_dataloader(batch_size=32, split=\"test\")\n",
    "    total_samples = len(dataloader)\n",
    "    \n",
    "    results = []\n",
    "    process_single_sample = False\n",
    "    \n",
    "    for i, batch in enumerate(tqdm.tqdm(dataloader)):        \n",
    "        question = batch[\"question\"][0]\n",
    "        print(f\"  Question: {question[:50]}...\")\n",
    "        \n",
    "        prompt = f\"Question: {question}\\nAnswer:\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(**inputs, max_new_tokens=50, max_time=30,\n",
    "                                         num_return_sequences=1, do_sample=True, \n",
    "                                         temperature=0.7, top_p=0.95,\n",
    "                                         pad_token_id=tokenizer.eos_token_id)\n",
    "            \n",
    "            generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            answer = generated_text.split(\"Answer:\")[-1].strip()\n",
    "            print(f\"  Answer generated: {answer[:50]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating answer: {str(e)}\")\n",
    "            answer = \"Error: Failed to generate answer\"\n",
    "        \n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"generated answer\": answer,\n",
    "            \"ground truth\": batch[\"answer\"][0]\n",
    "        })\n",
    "        \n",
    "        torch.cuda.empty_cache()  \n",
    "        \n",
    "        if process_single_sample:\n",
    "            break \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff995c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load model from local path: checkpoints/Qwen2-1.5B\n",
      "Loaded 1319 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Question: Janet’s ducks lay 16 eggs per day. She eats three ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/42 [00:02<01:28,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def daily_earnings():\n",
      "    \"\"\"Janet’s duc...\n",
      "  Question: John takes care of 10 dogs.  Each dog takes .5 hou...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2/42 [00:03<00:58,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def total_hours_spent():\n",
      "    \"\"\"John tak...\n",
      "  Question: Sophia is thinking of taking a road trip in her ca...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/42 [00:04<00:48,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def miles_per_tank():\n",
      "    \"\"\"Sophia is t...\n",
      "  Question: Harry slept 9 hours last night. His friend James s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4/42 [00:05<00:43,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Harry's sleep tim...\n",
      "  Question: Well's mother sells watermelons, peppers, and oran...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5/42 [00:06<00:40,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def total_cost():\n",
      "    \"\"\"Well's mother s...\n",
      "  Question: A tank of water has a depth of 17 feet on Monday. ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 6/42 [00:07<00:37,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the variab...\n",
      "  Question: Tom plants 10 trees a year.  Every year he also ch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 7/42 [00:08<00:36,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "initial_number_of_trees = 50\n",
      "trees_plant...\n",
      "  Question: Carlos and Benji are at the beach. Carlos rents a ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 8/42 [00:09<00:34,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def total_rental_cost():\n",
      "    \"\"\"Carlos a...\n",
      "  Question: Brady is counting the money in his piggy bank. He ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 9/42 [00:10<00:33,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "pennies = 100\n",
      "nickels = 40\n",
      "dimes = 20\n",
      "do...\n",
      "  Question: A landscaping company is delivering flagstones to ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 10/42 [00:11<00:31,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: The total weight of 80 flagstones is 80*75 = 6000 ...\n",
      "  Question: At the beginning of the party, there were 25 men a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 11/42 [00:11<00:30,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the initia...\n",
      "  Question: After Andrea saved some money, she then spent the ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 12/42 [00:12<00:29,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def money_saved():\n",
      "    \"\"\"After Andrea s...\n",
      "  Question: Mr. Ruther sold 3/5 of his land and had 12.8 hecta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 13/42 [00:13<00:28,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: Mr. Ruther sold 3/5 of his land, so he had 1 - 3/5...\n",
      "  Question: A herd consists of camels and dromedaries. There a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 14/42 [00:14<00:27,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import symbols, Eq, solve\n",
      "\n",
      "# ...\n",
      "  Question: A salesman bought a case of 48 sneakers for $576. ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 15/42 [00:15<00:26,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "# profit is total revenue minus total co...\n",
      "  Question: Ben has 4 tubes of blue paint and 3 tubes of yello...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 16/42 [00:16<00:25,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def jasper_paint_tubes():\n",
      "    \"\"\"Ben has...\n",
      "  Question: Hannah needs to drink 60 ml of water for each kilo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 17/42 [00:17<00:24,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: Each lap is 0.25 km, so 8 laps are 8*0.25 = 2 km.\n",
      "...\n",
      "  Question: Jeff and Brad are trying to divide 100 dollars bet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 18/42 [00:18<00:23,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: Let's solve this problem using Python's sympy libr...\n",
      "  Question: Michael is replacing the carpet in his bedroom.  T...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 19/42 [00:19<00:22,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: The cost for removing the old carpet is $4 per squ...\n",
      "  Question: Joe has $50 to buy an outfit for his new field tri...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 20/42 [00:20<00:21,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the variab...\n",
      "  Question: Bill is ordering a new truck. He has decided to pu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 21/42 [00:21<00:20,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "# base price\n",
      "base_price = 30000\n",
      "# king c...\n",
      "  Question: Christina records her mood every day on a calendar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 22/42 [00:22<00:19,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the number...\n",
      "  Question: Gerald and Julia divided $100 in the ratio 3:2. If...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 23/42 [00:23<00:18,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def money_left():\n",
      "    \"\"\"Gerald and Juli...\n",
      "  Question: Boris has 100 apples. Beck has 23 fewer apples tha...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 24/42 [00:24<00:17,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def apple_difference():\n",
      "    \"\"\"Boris has...\n",
      "  Question: In one hour, Ezra read twice as many books as Ahme...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 25/42 [00:25<00:16,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the variab...\n",
      "  Question: Pierson scored 278 points in one game of bowling. ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 26/42 [00:26<00:15,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def total_points():\n",
      "    \"\"\"Pierson score...\n",
      "  Question: Roy has saved 40% more in money earned by chores t...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 27/42 [00:27<00:14,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def money_saved_by_roy():\n",
      "    \"\"\"Roy has...\n",
      "  Question: George, a grade six teacher, ordered 600 burritos ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 28/42 [00:28<00:13,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "# 600 burritos for 50 students\n",
      "number_of...\n",
      "  Question: John rents his car out 10 times a month for 3 hour...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 29/42 [00:29<00:12,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def calculate_profit():\n",
      "    \"\"\"John rent...\n",
      "  Question: Rita hand-picks Junebugs off of her plants every s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 30/42 [00:30<00:11,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "junebugs_removed_on_monday = 39\n",
      "junebugs...\n",
      "  Question: A pirate crew is digging for buried treasure on th...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [00:31<00:10,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def holes_dug_on_fourth_day():\n",
      "    \"\"\"A ...\n",
      "  Question: Buford writes many checks every year.  Once per mo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 32/42 [00:32<00:09,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def total_checks():\n",
      "    \"\"\"Buford writes...\n",
      "  Question: Suzanne sold 80 cookies for $1 each and 60 cupcake...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 33/42 [00:33<00:08,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "number_of_cookies = 80\n",
      "price_per_cookie ...\n",
      "  Question: Greg puts clean sheets on 4 twin beds and 1 king s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 34/42 [00:34<00:07,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def total_laundry_loads():\n",
      "    \"\"\"Greg p...\n",
      "  Question: There are 6 periods in the day for a normal studen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 35/42 [00:35<00:06,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def total_learning_time():\n",
      "    \"\"\"There ...\n",
      "  Question: John visits his parents twice a month.  It takes h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 36/42 [00:36<00:05,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def miles_driven():\n",
      "    \"\"\"John visits h...\n",
      "  Question: Mark buys one lottery ticket with a 20% chance of ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 37/42 [00:37<00:04,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: The probability of Mark winning the first ticket i...\n",
      "  Question: To heat during the winter, Ali ordered 850 kilos o...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 38/42 [00:38<00:03,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: Ali ordered 850 kilos of coal, and each bag contai...\n",
      "  Question: A bus has a capacity of 200 people. When it depart...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 39/42 [00:39<00:02,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def remaining_capacity():\n",
      "    \"\"\"A bus h...\n",
      "  Question: Jason works as a salesperson at a car dealership. ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 40/42 [00:40<00:01,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def telephone_calls_needed():\n",
      "    \"\"\"Jas...\n",
      "  Question: Steve put together a puzzle that took 10 hours of ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 41/42 [00:41<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the variab...\n",
      "  Question: Tom's restaurant gets 6 reservations a night.  The...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:42<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "# each reservation gets 2 meals\n",
      "meals_pe...\n",
      "Processed 42 questions from GSM8K dataset\n",
      "Results saved to results/llm_inference_results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = llm_inference()\n",
    "print(f\"Processed {len(results)} questions from GSM8K dataset\")\n",
    "\n",
    "# Save results to a json file\n",
    "output_file = \"results/llm_inference_results.json\"\n",
    "if not os.path.exists(\"results\"):\n",
    "    os.makedirs(\"results\")\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "print(f\"Results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e015da",
   "metadata": {},
   "source": [
    "### Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bde1e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import os\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7859830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model():\n",
    "    # 加载基础模型\n",
    "    model, tokenizer, device = load_qwen_model()\n",
    "    \n",
    "    # 检查pad_token是否存在\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # 自定义微调数据集类\n",
    "    class FinetuneGSM8KDataset(Dataset):\n",
    "        def __init__(self, split, tokenizer, max_length=512):\n",
    "            root = \"datasets/grade_school_math/data\"\n",
    "            file_path = os.path.join(root, f\"{split}.jsonl\")\n",
    "            with open(file_path, 'r') as f:\n",
    "                self.data = [json.loads(line) for line in f]\n",
    "            self.tokenizer = tokenizer\n",
    "            self.max_length = max_length\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.data)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            item = self.data[idx]\n",
    "            question = item[\"question\"]\n",
    "            answer = item[\"answer\"]\n",
    "            \n",
    "            # 构造模型输入格式\n",
    "            prompt = f\"Question: {question}\\nAnswer: {answer}\"\n",
    "            inputs = self.tokenizer(\n",
    "                prompt,\n",
    "                max_length=self.max_length,\n",
    "                padding=False,\n",
    "                truncation=True,\n",
    "                return_tensors=None\n",
    "            )\n",
    "            \n",
    "            # 分离输入和标签（问答分离）\n",
    "            input_ids = inputs[\"input_ids\"]\n",
    "            # 找到Answer:的位置来分割输入输出\n",
    "            answer_prefix = f\"\\nAnswer: \"\n",
    "            prompt_text = f\"Question: {question}{answer_prefix}\"\n",
    "            prompt_len = len(self.tokenizer.encode(prompt_text, add_special_tokens=False))\n",
    "            \n",
    "            # 设置标签（只计算答案部分的loss）\n",
    "            labels = [-100]*prompt_len + input_ids[prompt_len:]\n",
    "            \n",
    "            return {\n",
    "                \"input_ids\": input_ids,\n",
    "                \"attention_mask\": [1]*len(input_ids),\n",
    "                \"labels\": labels\n",
    "            }\n",
    "\n",
    "    # 动态填充collate函数\n",
    "    def collate_fn(batch):\n",
    "        pad_token_id = tokenizer.pad_token_id\n",
    "        max_length = max(len(item[\"input_ids\"]) for item in batch)\n",
    "        \n",
    "        padded_batch = {\n",
    "            \"input_ids\": [],\n",
    "            \"attention_mask\": [],\n",
    "            \"labels\": []\n",
    "        }\n",
    "        \n",
    "        for item in batch:\n",
    "            pad_len = max_length - len(item[\"input_ids\"])\n",
    "            padded_batch[\"input_ids\"].append(\n",
    "                item[\"input_ids\"] + [pad_token_id]*pad_len\n",
    "            )\n",
    "            padded_batch[\"attention_mask\"].append(\n",
    "                item[\"attention_mask\"] + [0]*pad_len\n",
    "            )\n",
    "            padded_batch[\"labels\"].append(\n",
    "                item[\"labels\"] + [-100]*pad_len\n",
    "            )\n",
    "        \n",
    "        # 转换为tensor并移到设备\n",
    "        for key in padded_batch:\n",
    "            padded_batch[key] = torch.tensor(padded_batch[key], dtype=torch.long).to(device)\n",
    "            \n",
    "        return padded_batch\n",
    "\n",
    "    # 创建数据加载器\n",
    "    train_dataset = FinetuneGSM8KDataset(\"train\", tokenizer)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=4,  # 根据GPU显存调整\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "\n",
    "    # 训练配置\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    num_epochs = 3\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer,\n",
    "        num_warmup_steps=int(0.1*total_steps),\n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    # 训练循环\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm.tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            \n",
    "            # 梯度裁剪\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
    "        \n",
    "        # 打印epoch统计信息\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1} completed. Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # 保存微调后的模型\n",
    "    finetuned_path = \"checkpoints/Qwen2-1.5B-finetuned\"\n",
    "    model.save_pretrained(finetuned_path)\n",
    "    tokenizer.save_pretrained(finetuned_path)\n",
    "    print(f\"Fine-tuned model saved to {finetuned_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b895f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 修改后的推理函数（加载微调后的模型）\n",
    "def llm_inference_after_finetune():\n",
    "    # 加载微调后的模型\n",
    "    finetuned_path = \"checkpoints/Qwen2-1.5B-finetuned\"\n",
    "    print(f\"Loading fine-tuned model from {finetuned_path}\")\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(finetuned_path, trust_remote_code=True)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(finetuned_path, trust_remote_code=True).to(device)\n",
    "    \n",
    "    dataloader = gsm8k_dataloader(batch_size=32, split=\"test\")\n",
    "    total_samples = len(dataloader)\n",
    "    \n",
    "    results = []\n",
    "    process_single_sample = False\n",
    "    \n",
    "    for i, batch in enumerate(tqdm.tqdm(dataloader)):        \n",
    "        question = batch[\"question\"][0]\n",
    "        print(f\"  Question: {question[:50]}...\")\n",
    "        \n",
    "        prompt = f\"Question: {question}\\nAnswer:\"\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        \n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                outputs = model.generate(**inputs, max_new_tokens=50, max_time=30,\n",
    "                                         num_return_sequences=1, do_sample=True, \n",
    "                                         temperature=0.7, top_p=0.95,\n",
    "                                         pad_token_id=tokenizer.eos_token_id)\n",
    "            \n",
    "            generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            answer = generated_text.split(\"Answer:\")[-1].strip()\n",
    "            print(f\"  Answer generated: {answer[:50]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error generating answer: {str(e)}\")\n",
    "            answer = \"Error: Failed to generate answer\"\n",
    "        \n",
    "        results.append({\n",
    "            \"question\": question,\n",
    "            \"generated answer\": answer,\n",
    "            \"ground truth\": batch[\"answer\"][0]\n",
    "        })\n",
    "        \n",
    "        torch.cuda.empty_cache()  \n",
    "        \n",
    "        if process_single_sample:\n",
    "            break \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "084d5131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load model from local path: checkpoints/Qwen2-1.5B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1869/1869 [22:37<00:00,  1.38it/s, loss=0.2774]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Average Loss: 0.4077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1869/1869 [22:36<00:00,  1.38it/s, loss=0.0822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Average Loss: 0.2379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1869/1869 [22:44<00:00,  1.37it/s, loss=0.1079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Average Loss: 0.0695\n",
      "Fine-tuned model saved to checkpoints/Qwen2-1.5B-finetuned\n",
      "Attempting to load model from local path: checkpoints/Qwen2-1.5B\n",
      "Loaded 1319 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/42 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Question: Janet’s ducks lay 16 eggs per day. She eats three ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/42 [00:01<00:51,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: Janet has 16-3 = 13 eggs left after breakfast.\n",
      "She...\n",
      "  Question: John takes care of 10 dogs.  Each dog takes .5 hou...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 2/42 [00:02<00:43,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: Each dog takes 0.5 hours a day to walk and take ca...\n",
      "  Question: Sophia is thinking of taking a road trip in her ca...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3/42 [00:03<00:40,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def miles_per_tank():\n",
      "    \"\"\"Sophia is t...\n",
      "  Question: Harry slept 9 hours last night. His friend James s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 4/42 [00:04<00:38,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def sleep_difference():\n",
      "    \"\"\"Harry sle...\n",
      "  Question: Well's mother sells watermelons, peppers, and oran...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 5/42 [00:05<00:36,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def total_spent():\n",
      "    \"\"\"Well's mother ...\n",
      "  Question: A tank of water has a depth of 17 feet on Monday. ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 6/42 [00:06<00:35,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def water_depth_on_wednesday():\n",
      "    \"\"\"A...\n",
      "  Question: Tom plants 10 trees a year.  Every year he also ch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 7/42 [00:07<00:34,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def remaining_trees():\n",
      "    \"\"\"Tom plants...\n",
      "  Question: Carlos and Benji are at the beach. Carlos rents a ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 8/42 [00:08<00:33,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the variab...\n",
      "  Question: Brady is counting the money in his piggy bank. He ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 9/42 [00:08<00:32,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "pennies = 100\n",
      "nickels = 40\n",
      "dimes = 20\n",
      "do...\n",
      "  Question: A landscaping company is delivering flagstones to ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 10/42 [00:09<00:31,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def trucks_needed():\n",
      "    \"\"\"A landscapin...\n",
      "  Question: At the beginning of the party, there were 25 men a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 11/42 [00:10<00:29,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the initia...\n",
      "  Question: After Andrea saved some money, she then spent the ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 12/42 [00:11<00:28,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def money_saved():\n",
      "    \"\"\"After Andrea s...\n",
      "  Question: Mr. Ruther sold 3/5 of his land and had 12.8 hecta...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 13/42 [00:12<00:27,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: Mr. Ruther sold 3/5 of his land, which is 12.8 hec...\n",
      "  Question: A herd consists of camels and dromedaries. There a...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 14/42 [00:13<00:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def num_dromedaries():\n",
      "    \"\"\"A herd con...\n",
      "  Question: A salesman bought a case of 48 sneakers for $576. ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 15/42 [00:14<00:26,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def calculate_profit():\n",
      "    \"\"\"A salesma...\n",
      "  Question: Ben has 4 tubes of blue paint and 3 tubes of yello...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 16/42 [00:15<00:25,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the number...\n",
      "  Question: Hannah needs to drink 60 ml of water for each kilo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 17/42 [00:16<00:24,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def water_needed():\n",
      "    \"\"\"Hannah needs ...\n",
      "  Question: Jeff and Brad are trying to divide 100 dollars bet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 18/42 [00:17<00:23,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: Let's assume Brad gets $x$ dollars.\n",
      "Then Jeff gets...\n",
      "  Question: Michael is replacing the carpet in his bedroom.  T...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 19/42 [00:18<00:22,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "# carpet cost\n",
      "carpet_cost = 12\n",
      "# padding...\n",
      "  Question: Joe has $50 to buy an outfit for his new field tri...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 20/42 [00:19<00:21,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the variab...\n",
      "  Question: Bill is ordering a new truck. He has decided to pu...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 21/42 [00:20<00:20,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def total_truck_cost():\n",
      "    \"\"\"Bill is o...\n",
      "  Question: Christina records her mood every day on a calendar...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 22/42 [00:21<00:19,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: Christina had 12 good days, 8 bad days, and 8 neut...\n",
      "  Question: Gerald and Julia divided $100 in the ratio 3:2. If...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 23/42 [00:22<00:18,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: The ratio of Gerald's share to Julia's share is 3:...\n",
      "  Question: Boris has 100 apples. Beck has 23 fewer apples tha...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 24/42 [00:23<00:17,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def apple_difference():\n",
      "    \"\"\"Boris has...\n",
      "  Question: In one hour, Ezra read twice as many books as Ahme...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 25/42 [00:24<00:16,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: Ahmed read 300/2 = 150 books in one hour.\n",
      "Ezra has...\n",
      "  Question: Pierson scored 278 points in one game of bowling. ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 26/42 [00:25<00:15,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def total_points():\n",
      "    \"\"\"Pierson score...\n",
      "  Question: Roy has saved 40% more in money earned by chores t...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 27/42 [00:26<00:14,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: Roy saved 40% more than Anthony, so Roy saved $10....\n",
      "  Question: George, a grade six teacher, ordered 600 burritos ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 28/42 [00:27<00:13,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the variab...\n",
      "  Question: John rents his car out 10 times a month for 3 hour...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 29/42 [00:28<00:12,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "# number of hours rented\n",
      "rented_hours = ...\n",
      "  Question: Rita hand-picks Junebugs off of her plants every s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 30/42 [00:29<00:11,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "junebug_count_monday = 39\n",
      "junebug_count_...\n",
      "  Question: A pirate crew is digging for buried treasure on th...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 31/42 [00:30<00:10,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def holes_dug_fourth_day():\n",
      "    \"\"\"A pir...\n",
      "  Question: Buford writes many checks every year.  Once per mo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 32/42 [00:31<00:09,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: There are 12 months in a year.\n",
      "Buford writes a che...\n",
      "  Question: Suzanne sold 80 cookies for $1 each and 60 cupcake...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 33/42 [00:32<00:08,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the variab...\n",
      "  Question: Greg puts clean sheets on 4 twin beds and 1 king s...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 34/42 [00:33<00:07,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "# number of sheets to be washed per week...\n",
      "  Question: There are 6 periods in the day for a normal studen...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 35/42 [00:34<00:06,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def learning_time():\n",
      "    \"\"\"There are 6 ...\n",
      "  Question: John visits his parents twice a month.  It takes h...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 36/42 [00:35<00:05,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def total_miles():\n",
      "    \"\"\"John visits hi...\n",
      "  Question: Mark buys one lottery ticket with a 20% chance of ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 37/42 [00:35<00:04,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import Rational\n",
      "\n",
      "# Probabilit...\n",
      "  Question: To heat during the winter, Ali ordered 850 kilos o...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 38/42 [00:36<00:03,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def cost_of_order():\n",
      "    \"\"\"To heat duri...\n",
      "  Question: A bus has a capacity of 200 people. When it depart...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 39/42 [00:37<00:02,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def remaining_capacity():\n",
      "    \"\"\"A bus h...\n",
      "  Question: Jason works as a salesperson at a car dealership. ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 40/42 [00:38<00:01,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "def calculate_calls():\n",
      "    \"\"\"Jason work...\n",
      "  Question: Steve put together a puzzle that took 10 hours of ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 41/42 [00:39<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "from sympy import *\n",
      "\n",
      "# Define the variab...\n",
      "  Question: Tom's restaurant gets 6 reservations a night.  The...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [00:40<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Answer generated: ```python\n",
      "# Tom's restaurant gets 6 reservations a...\n",
      "Inference results saved to results/finetuned_llm_results.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# 执行微调\n",
    "finetune_model()\n",
    "\n",
    "# 使用微调后的模型进行推理\n",
    "results = llm_inference()\n",
    "\n",
    "# 保存结果\n",
    "output_file = \"results/finetuned_llm_results.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "print(f\"Inference results saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
